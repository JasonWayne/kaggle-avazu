{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Lambda, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K\n",
    "from sklearn import metrics\n",
    "from keras.regularizers import WeightRegularizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dummy_empty = 2 ** 17\n",
    "\n",
    "context_train = []\n",
    "ad_train = []\n",
    "y_train = []\n",
    "\n",
    "\n",
    "with open('../../data/click-all-train.thumb') as f:\n",
    "    for line in f:\n",
    "        label, context, a,b,c,d, ad, e,f,g,h = line.split(\"\\t\")\n",
    "        y_train.append(int(label))\n",
    "        context_train.append(map(lambda x: int(x) if x else dummy_empty, context.strip().split(\" \")))\n",
    "        ad_train.append(map(lambda x: int(x) if x else dummy_empty, ad.strip().split(\" \")))\n",
    "\n",
    "\n",
    "\n",
    "context_test = []\n",
    "ad_test = []\n",
    "y_test = []\n",
    "\n",
    "with open('../../data/click-all-test.thumb') as f:\n",
    "    label, context_name, a,b,c,d, ad_name, c,f,g,h = line.split(\"\\t\")\n",
    "    y_test.append(int(label))\n",
    "    context_test.append(map(lambda x: int(x) if x else dummy_empty, context_name.strip().split(\" \")))\n",
    "    ad_test.append(map(lambda x:  int(x) if x else dummy_empty, ad_name.strip().split(\" \")))\n",
    "    \n",
    "with open('../../data/click-all-test.thumb') as f:\n",
    "    for line in f:\n",
    "        label, context, a,b,c,d,ad ,e,f,g,h= line.strip().split(\"\\t\")\n",
    "        y_test.append(int(label))\n",
    "        context_test.append(map(lambda x: int(x) if x else dummy_empty, context.strip().split(\" \")))\n",
    "        ad_test.append(map(lambda x: int(x) if x else dummy_empty, ad.strip().split(\" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dummy_empty = 2 ** 17\n",
    "\n",
    "context_train = []\n",
    "ad_train = []\n",
    "y_train = []\n",
    "with open('../../data/click-all-train.thumb') as f:\n",
    "    for line in f:\n",
    "        label, context,a,b,c,d, ad,e,f,g,h = line.strip().split(\"\\t\")\n",
    "        y_train.append(int(label))\n",
    "        context_train.append(map(lambda x: int(x) if x else dummy_empty, context.strip().split(\" \")))\n",
    "        ad_train.append(map(lambda x: int(x) if x else dummy_empty, ad.strip().split(\" \")))\n",
    "        \n",
    "        \n",
    "context_test = []\n",
    "ad_test = []\n",
    "y_test = []\n",
    "with open('../../data/click-all-test.thumb') as f:\n",
    "    for line in f:\n",
    "        label, context, a,b,c,d,ad ,e,f,g,h= line.strip().split(\"\\t\")\n",
    "        y_test.append(int(label))\n",
    "        context_test.append(map(lambda x: int(x) if x else dummy_empty, context.strip().split(\" \")))\n",
    "        ad_test.append(map(lambda x: int(x) if x else dummy_empty, ad.strip().split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "maxlen = 15\n",
    "\n",
    "\n",
    "context_train = sequence.pad_sequences(context_train, maxlen=maxlen)\n",
    "\n",
    "ad_train = sequence.pad_sequences(ad_train, maxlen=maxlen)\n",
    "\n",
    "\n",
    "context_test = sequence.pad_sequences(context_test, maxlen=maxlen)\n",
    "\n",
    "\n",
    "ad_test = sequence.pad_sequences(ad_test, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def means(x):\n",
    "    return K.mean(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s - loss: 0.7760 - fmeasure: 0.4777 - val_loss: 0.7049 - val_fmeasure: 0.0000e+00\n",
      "train auc -> 0.63756744687\n",
      "test auc -> 0.513149960587\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s - loss: 0.6896 - fmeasure: 0.5723 - val_loss: 0.6930 - val_fmeasure: 0.0080\n",
      "train auc -> 0.794927224742\n",
      "test auc -> 0.524383080118\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s - loss: 0.6304 - fmeasure: 0.6499 - val_loss: 0.7016 - val_fmeasure: 0.6203\n",
      "train auc -> 0.877940566689\n",
      "test auc -> 0.53582632773\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s - loss: 0.5907 - fmeasure: 0.7010 - val_loss: 0.7179 - val_fmeasure: 0.5813\n",
      "train auc -> 0.928460413397\n",
      "test auc -> 0.530473173308\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s - loss: 0.5432 - fmeasure: 0.7432 - val_loss: 0.7578 - val_fmeasure: 0.5967\n",
      "train auc -> 0.958013877117\n",
      "test auc -> 0.526501686546\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      " 2592/10000 [======>.......................] - ETA: 0s - loss: 0.4949 - fmeasure: 0.7935\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-01f346806a1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../../model/weights.epoch'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.hdf5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mweight_save_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontext_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mad_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontext_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mad_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweight_save_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontext_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mad_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/meituan/apps/venv/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    650\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/opt/meituan/apps/venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1111\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/meituan/apps/venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# last batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/meituan/apps/venv/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/meituan/apps/venv/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nb_sample'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/meituan/apps/venv/lib/python2.7/site-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values, force)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\b\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mnumdigits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/meituan/apps/venv/lib/python2.7/site-packages/ipykernel/iostream.pyc\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "from keras.layers import Merge\n",
    "\n",
    "max_features = 2 ** 17 + 1\n",
    "batch_size = 32\n",
    "embedding_dims = 3\n",
    "\n",
    "\n",
    "context_name = Sequential()\n",
    "context_name.add(Embedding(input_dim=max_features, output_dim=embedding_dims, init='glorot_uniform'))\n",
    "context_name.add(Dropout(0.5))\n",
    "context_name.add(Lambda(means, output_shape=(embedding_dims,)))\n",
    "\n",
    "\n",
    "ad_name = Sequential()\n",
    "ad_name.add(Embedding(input_dim=max_features, output_dim=embedding_dims, init='glorot_uniform'))\n",
    "ad_name.add(Dropout(0.5))\n",
    "ad_name.add(Lambda(means, output_shape=(embedding_dims,)))\n",
    "\n",
    "merged = Merge([context_name, ad_name], mode='concat')\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(merged)\n",
    "\n",
    "final_model.add(Dense(20))\n",
    "final_model.add(BatchNormalization())\n",
    "final_model.add(LeakyReLU(alpha=.01))\n",
    "final_model.add(Dropout(0.5))\n",
    "final_model.add(Dense(1))\n",
    "final_model.add(BatchNormalization())\n",
    "final_model.add(Activation('sigmoid'))\n",
    "\n",
    "final_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['fmeasure'])\n",
    "\n",
    "model_path = ''\n",
    "for i in range(10):\n",
    "    if model_path != '':\n",
    "        final_model.load_weights(model_path)\n",
    "    model_path = '../../model/weights.epoch' + str(i) + \"_\" + str(int(time.time())) + '.hdf5'\n",
    "    weight_save_callback = ModelCheckpoint(model_path, monitor='val_loss', verbose=0, save_best_only=False, mode='auto')\n",
    "    final_model.fit([context_train, ad_train], y_train, batch_size=batch_size, validation_data=([context_test,ad_test], y_test), nb_epoch=1, callbacks=[weight_save_callback])\n",
    "    \n",
    "    y_pred = final_model.predict([context_train, ad_train])[:, 0]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_train, y_pred)\n",
    "    print \"train auc -> \" + str(metrics.auc(fpr, tpr))\n",
    "    \n",
    "    y_pred = final_model.predict([context_test, ad_test])[:, 0]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    print \"test auc -> \" + str(metrics.auc(fpr, tpr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proc = subprocess.Popen('./fasttext print-vectors ~/Downloads/typeid_areaid_poiid_corpus_20161206_night.bin < test_seg.txt', shell=True, stdout=subprocess.PIPE)\n",
    "arr = np.loadtxt(proc.stdout)\n",
    "\n",
    "txt = []\n",
    "with open('test_seg.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        txt.append(line.rstrip().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, mpld3.show() is not the best command\n",
      "      to use. Consider using mpld3.display(), or mpld3.enable_notebook().\n",
      "      See more information at http://mpld3.github.io/quickstart.html.\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8891/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Dec/2016 16:20:14] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2016 16:20:14] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2016 16:20:14] \"GET /mpld3.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    " \n",
    "\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "mpld3.enable_notebook()\n",
    "\n",
    "ChineseFont1 = FontProperties(fname = '/System/Library/Fonts/STHeiti Medium.ttc')\n",
    " \n",
    "\n",
    "# wv = arr\n",
    "# vocabulary = txt\n",
    "\n",
    "plt.scatter(Y[:, 0], Y[:, 1])\n",
    "for label, x, y in zip(vocabulary, Y[:, 0], Y[:, 1]):\n",
    "    # plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points', fontproperties=ChineseFont1)\n",
    "    plt.text(x, y, label)\n",
    "    \n",
    "\n",
    "\n",
    "Y = Y[:60, :]\n",
    "\n",
    "\n",
    "plt.scatter(Y[:, 0], Y[:, 1])\n",
    "for label, x, y in zip(vocabulary, Y[:, 0], Y[:, 1]):\n",
    "    # plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points', fontproperties=ChineseFont1)\n",
    "    plt.text(x, y, label)\n",
    "# mpld3.display()\n",
    "\n",
    "\n",
    "\n",
    "mpld3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, mpld3.show() is not the best command\n",
      "      to use. Consider using mpld3.display(), or mpld3.enable_notebook().\n",
      "      See more information at http://mpld3.github.io/quickstart.html.\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8891/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Dec/2016 16:18:36] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2016 16:18:36] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2016 16:18:36] \"GET /mpld3.js HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stopping Server...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112d31e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
